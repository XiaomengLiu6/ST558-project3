---
title: "project3"
author: "Xiaomeng Liu"
date: "2023-11-05"
output:
  github_document:
    toc: true
    toc_depth: 3
    number_sections: false
params:
  ed_level: "4"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
paste0("This is the automated generated md file for the education level ",params$ed_level)
```

# Goal

We analyzed a Diabetes Health Indicator Dataset. We were doing a separate analysis (basic EDA and the fitting/selection of predictive models) for each of these five Education groups using a single .Rmd file. In the file, we had a parameter corresponding to which Education level we were looking at and we subset the data to only use those observations for
that analysis. We created render() code similar to the lecture to make the process of creating the five separate analysis simple to do.

# library

All the libraries used in this file are included here.
```{r, message=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(caret)
library(ModelMetrics)
library(rotationForest)
```

# Introduction section

This is the section that we briefly describes the data and the variables you have to work with (just discuss the ones we use in our analysis), and describes the purpose of our EDA and modeling, along with the end result we would be creating.

The analyses presented here are based on the Diabetes Health Indicators Dataset, made available by kaggle.com at https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/.  The specific dataset upon which this analysis is based (diabetes_binary_health_indicators_BRFSS2015.csv) is comprised of approximately 250,000 records, each having a dichotomous 0/1 indication of no diabetes vs. diabetes/pre-diabetes.  In addition, the datafile contains roughly 20 feature variables of various types, including continuous (e.g. body mass index), categorical (e.g. education level), and dummy indicators (e.g. whether the patient has high blood pressure).

The analytic approach taken here is to control for patients' level of education by conducting a separate analysis (i.e. exploratory data analysis + predictive modelling) for each of five education levels:  (1) 8th grade or lower; (2) grade 9 through 11; (3) high school credential; (4) some college or technical school; and (5) bachelors degree or higher.  The outcome measure of interest for all analyses will be the dichotomous diabetes indicator.

```{r}
  #per https://www.cdc.gov/brfss/annual_data/2015/pdf/codebook15_llcp.pdf,
  #here are value meanings for the education variable:
    #1 = Never attended school or only kindergarten 
    #2 = Grades 1 through 8 (Elementary)
    #3 = Grades 9 through 11 (Some high school)
    #4 = Grade 12 or GED (High school graduate) 
    #5 = College 1 year to 3 years (Some college or technical school)
    #6 = College 4 years or more (College graduate)
    #9 = Refused

#and here are values for other non-binary variables:
  #income
    #1 = Less than $10,000
    #2 = Less than $15,000 ($10,000 to less than $15,000)
    #3 = Less than $20,000 ($15,000 to less than $20,000)
    #4 = Less than $25,000 ($20,000 to less than $25,000)
    #5 = Less than $35,000 ($25,000 to less than $35,000)
    #6 = Less than $50,000 ($35,000 to less than $50,000)
    #7 = Less than $75,000 ($50,000 to less than $75,000)
    #8 = $75,000 or more
    #77 = Don’t know/Not sure
    #99 = Refused

  #Age
    #1 = Age 18 to 24
    #2 = Age 25 to 29
    #3 = Age 30 to 34
    #4 = Age 35 to 39
    #5 = Age 40 to 44
    #6 = Age 45 to 49
    #7 = Age 50 to 54
    #8 = Age 55 to 59
    #9 = Age 60 to 64
    #10 = Age 65 to 69
    #11 = Age 70 to 74
    #12 = Age 75 to 79
    #13 = Age 80 or older
    #14 = Don’t know/Refused/Missing

  #GenHlth
    #1 = excellent 
    #2 = very good 
    #3 = good 
    #4 = fair 
    #5 = poor 

  #Sex is coded as 0 = female, 1 = male
```

# Data

Before conducting analyses, we will read in the csv datafile, collapse education levels of "Never attended school or only kindergarten" and "Grades 1 through 8" into a single category, and convert categorical variables into R factors.

### Read in the data
```{r}
#read in csv file
diabetes<-read.csv("diabetes_binary_health_indicators_BRFSS2015.csv")
```

### Combine 1 and 2 Education levels
```{r}
#create collapsed version of education variable
diabetes$Education <- recode(diabetes$Education, `1` = 2)
table(diabetes$Education)
```

### Convert variables to factors
```{r}
#create factor version of variables, where applicable
#in order to facilitate the EDA, for now at least, we'll retain both the factor version and the numeric version of each variable (we may need to drop one version, though, before running models)
diabetes$Diabetes_binary_f	 <- as.factor(diabetes$Diabetes_binary)
diabetes$HighBP_f	 <- as.factor(diabetes$HighBP)
diabetes$HighChol_f	 <- as.factor(diabetes$HighChol)
diabetes$CholCheck_f	 <- as.factor(diabetes$CholCheck)
#BMI -- this is a continuous var
diabetes$Smoker_f	 <- as.factor(diabetes$Smoker)
diabetes$Stroke_f	 <- as.factor(diabetes$Stroke)
diabetes$HeartDiseaseorAttack_f	 <- as.factor(diabetes$HeartDiseaseorAttack)
diabetes$PhysActivity_f	 <- as.factor(diabetes$PhysActivity)
diabetes$Fruits_f	 <- as.factor(diabetes$Fruits)
diabetes$Veggies_f	 <- as.factor(diabetes$Veggies)
diabetes$HvyAlcoholConsump_f	 <- as.factor(diabetes$HvyAlcoholConsump)
diabetes$AnyHealthcare_f	 <- as.factor(diabetes$AnyHealthcare)
diabetes$NoDocbcCost_f	 <- as.factor(diabetes$NoDocbcCost)
diabetes$GenHlth_f <-  as.factor(diabetes$GenHlth)
#MentHlth -- this is a continuous var
#PhysHlth -- this is a continuous var
diabetes$DiffWalk_f	 <- as.factor(diabetes$DiffWalk)
diabetes$Sex_f	 <- as.factor(diabetes$Sex)
diabetes$Age_f	 <- as.factor(diabetes$Age)
diabetes$Education_f	 <- as.factor(diabetes$Education)
diabetes$Income_f	 <- as.factor(diabetes$Income)
```

## subset to specific level of education per *params* setting
```{r}
#subset to specific level of education per *params* setting
temp <- subset(diabetes, Education==params$ed_level)
```

# Summarizations

We produce some basic (but meaningful) summary statistics and plots about the data we are working
with (especially as it relates to our response). We did our EDA on the full (subsetted to a single Education
level) data.

Prior to modelling our data, we will first conduct an exploratory data analysis (EDA).  Our EDA will begin by confirming that we are working with the desired set of cases, i.e. the set of cases corresponding to a single level of the categorical "education" measure.  

```{r}
#confirm that we're working with the desired set of cases
table(temp$Education, temp$Education_f)
ggplot(data=temp, aes(x=Education_f)) + 
  geom_dotplot(binwidth = .05, method = "histodot") + 
  labs(title = "confirm that we're working with the desired set of cases")
```

```{r}
# a simple EDA
str(temp)
#MentHlth -- this is a continuous var
#PhysHlth -- this is a continuous var
#BMI -- this is a continuous var

nume<-cbind(temp$BMI,temp$MentHlth, temp$PhysHlth)
as.table(cbind(min(temp$BMI),sd(temp$BMI)))
table(temp$CholCheck_f)
temp%>%summarize(mean=mean(varb),median=median(varb),std=sd(varb))
```

After confirming correct data subsetting, for each factor variable in the dataset, we have calculated the prevalence of diabetes at each level of said factor in hopes of identifying any bi-variate associations with diabetes.  In addition, for each factor variable, we graphically display (1) the relative frequency of patients within factor levels, and (2) the proportion of patients within each level of each factor that do and do not have diabetes.

For continuous predictor variables, we have generated a correlation matrix (the outcome of interest is also included in this correlation matrix).  We also generate density plots and boxplots for each continuous predictor using the dichotomous outcome measure as a "by" variable for each of these plots.

```{r}
#function to check prevalence of diabetes at each level of each factor, and generate corresponding plots
#(I still need to flesh out this function such that it labels the plots)
explore <- function(by_var)
{
results1 <- temp %>%
  group_by({{by_var}}) %>%
  summarize(diabetes_rate = mean(Diabetes_binary))
    #passing variable names to function using curly brackets:
    #https://stackoverflow.com/questions/63433728/how-do-i-pass-a-variable-name-to-an-argument-in-a-function
print(results1)

results2 <- ggplot(data=temp, aes(x={{by_var}}, fill=Diabetes_binary_f)) + 
  geom_bar(stat="count") +
  labs(title = "Presence of diabetes, by select factors")
print(results2)
#Xiaomeng, I cant figure out how to pass a variable name into the title of each figure (and thus the generic title wording currently used here)
}

#probably need to run the above function for at least the sex, age, and income variables, but may not need to run it for this entire list
explore(by_var = HighBP_f)
explore(by_var = HighChol_f)
explore(by_var = CholCheck_f)
explore(by_var = Smoker_f)
explore(by_var = Stroke_f)
explore(by_var = HeartDiseaseorAttack_f)
explore(by_var = PhysActivity_f)
explore(by_var = Fruits_f)
explore(by_var = Veggies_f)
explore(by_var = HvyAlcoholConsump_f)
explore(by_var = AnyHealthcare_f)
explore(by_var = NoDocbcCost_f)
explore(by_var = GenHlth_f)
explore(by_var = DiffWalk_f)
explore(by_var = Sex_f)
explore(by_var = Age_f)
explore(by_var = Income_f)



#correlation matrix (outcome var x continuous vars)
corr_vars <-
  temp %>% select(c(Diabetes_binary, BMI, MentHlth, PhysHlth))
correlation <- cor(corr_vars, method = "spearman")
corrplot(correlation, type = "upper", tl.pos = "lt")
corrplot(correlation, type = "lower", method = "number", add = TRUE, diag = FALSE, tl.pos = "n")



#density plots / boxplots (outcome var x continuous vars)
#I'm guessing we could just choose one or the other
ggplot(data=temp, aes(x=BMI, fill=Diabetes_binary_f)) + 
  geom_density(adjust = 0.5, alpha = 0.5) +
  labs(title = "BMI, by diabetes status")
ggplot(data=temp, aes(x=Diabetes_binary_f, y=BMI)) + geom_boxplot() +
  labs(title = "BMI, by diabetes status")

ggplot(data=temp, aes(x=MentHlth, fill=Diabetes_binary_f)) + 
  geom_density(adjust = 0.5, alpha = 0.5) +
  labs(title = "Number of poor mental health days, by diabetes status")
ggplot(data=temp, aes(x=Diabetes_binary_f, y=MentHlth)) + geom_boxplot() +
  labs(title = "Number of poor mental health days, by diabetes status")

ggplot(data=temp, aes(x=PhysHlth, fill=Diabetes_binary_f)) + 
  geom_density(adjust = 0.5, alpha = 0.5) +
  labs(title = "Number of poor physical health days, by diabetes status")
bp3 <- ggplot(data=temp, aes(x=Diabetes_binary_f, y=PhysHlth)) + 
  geom_boxplot() + 
  labs(title = "Number of poor physical health days, by diabetes status")
```



# Modeling

We did some data cleaning and split the data into a training (70% of the data) and test set (30% of the data). Use set.seed() to make things reproducible. Then we will fit different models using different approach and provide explanations.

## Data cleaning

We made a data cleaning so that the model fitting methods would work better.

```{r}
#prior to running models, in instances where we have both a factor and a non-factor version of a given variable, we need to first drop the non-factor version of the variable
#we also need to drop both versions of the education variable (since it will not vary given that we've subset our data to a specific education level)
temp$Diabetes_binary	 <- NULL 
temp$HighBP	 <- NULL
temp$HighChol	 <- NULL
temp$CholCheck	 <- NULL
temp$Smoker	 <- NULL
temp$Stroke	 <- NULL
temp$HeartDiseaseorAttack	 <- NULL
temp$PhysActivity	 <- NULL
temp$Fruits	 <- NULL
temp$Veggies	 <- NULL
temp$HvyAlcoholConsump	 <- NULL
temp$AnyHealthcare	 <- NULL
temp$NoDocbcCost	 <- NULL 
temp$GenHlth <-  NULL
temp$DiffWalk	 <- NULL
temp$Sex	 <- NULL
temp$Age	 <- NULL
temp$Education	 <- NULL
temp$Education_f	 <- NULL
temp$Income	 <- NULL

# convert the 0 and 1 to no and yes for logLoss metric to work.
temp$Diabetes_binary_f<-ifelse(temp$Diabetes_binary_f==0,"no","yes")
temp$Diabetes_binary_f<-as.factor(temp$Diabetes_binary_f)
```

## train and test set split
```{r}
# set the seed
set.seed(433)
# split the training and testing
indextrain<-createDataPartition(y=temp$Diabetes_binary,p=0.7,list=FALSE)
ed_train<-temp[indextrain,]
ed_test<-temp[-indextrain,]
```

The goal is to create models for predicting the Diabetes_binary variable (using caret). We’ll use logLoss
as our metric to evaluate models. For all model types use logLoss with 5 fold cross-validation to select the
best model.

## what log loss is:

Log loss is a common evaluation metric for binary classification models. It measure the performance of a model by quantifying the difference between predicted probabilities and actual values. The more the predicted probability diverges from the actual value, the higher is the log-loss value.A lower log loss value means better predictions.Mathematically, log loss is the negative average of the log of correct predicted probabilities for each instance. 

We prefer it because log loss penalizes confident and incorrect predictors more heavily. It also provides a continuous and differentiable meausre of the model's performance, making it suitable of optimization algorithms. It could be interpreted as the logarithmic measure of the likelihood of the predicted probabilities aligning with the true labels.

### related links
Here are two website links I found useful for explaining this term:

https://www.analyticsvidhya.com/blog/2020/11/binary-cross-entropy-aka-log-loss-the-cost-function-used-in-logistic-regression/

https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a

## First method: logistic regression

### explanation of what a logistic regression is

The logistic regression is modeling average number of successes for a given x, 
i.e. probability of success.Basic logistic regression models success probability
using the logistic function $P(success|yard)=\frac{e^{\beta_0+\beta_1x}}{1+e^{\beta_0+\beta_1x}}$

### why we apply it to this kind of data
We have a response variable that is success/failure and it is perfect for fitting
a logistic regression mode. 

### fit three candidate logistic regression models and choose the best model.

```{r}
ed_logistic1<-train(Diabetes_binary_f~BMI+HighChol_f+HighBP_f,data=ed_train,
             method="glm", 
             metric="logLoss",
             trControl=trainControl(method = "cv",number = 5,classProbs = TRUE, summaryFunction = mnLogLoss),
             preProcess=c("center","scale")
)
ed_logistic1
```
```{r}
ed_logistic2<-train(Diabetes_binary_f~BMI+HighChol_f+HighBP_f+MentHlth+PhysActivity_f,data=ed_train,
             method="glm", 
             metric="logLoss",
             trControl=trainControl(method = "cv",number = 5,classProbs = TRUE, summaryFunction = mnLogLoss),
             preProcess=c("center","scale")
)
ed_logistic2
```
```{r}
ed_logistic3<-train(Diabetes_binary_f~.,data=ed_train,
             method="glm", 
             metric="logLoss",
             trControl=trainControl(method = "cv",number = 5,classProbs = TRUE, summaryFunction = mnLogLoss),
             preProcess=c("center","scale")
)
ed_logistic3
```
```{r}
# return the result
paste0("According to the results, the lowest logLoss is the model ", c("1","2","3")[which.min(c(ed_logistic1$results[2],ed_logistic2$results[2],ed_logistic3$results[2]))])
```

## Second method: Lasso logistic

Lasso models aim to leverage the bias-variance trade-off by purposefully introducing small amounts of bias while training the model, with the hope of ultimately decreasing variance (and thereby improving performance when using the model on test data). Instead of minimizing the residual sum of squares, the lasso method attempts to minimize the residual sum of squares *plus a so-called "shrinkage penalty"*.  In effect, the shrinkage penalty constrains regression coefficients, and in so doing, allows the model to better generalize to test data.  Here we use cross-validation to test different values for the shrinkage penalty in hopes of determining its optimal value, i.e. the shinkage penalty value which eliminates the greatest amount of variance in exchange for introduction of the smallest amount of bias.

```{r}
ed_lasso <- train(Diabetes_binary_f ~ ., data = ed_train,
  method = "glmnet",
  metric="logLoss",
  preProcess = c("center", "scale"),
  trControl = trainControl(method = "cv", number = 5, 
                           classProbs = TRUE, summaryFunction = mnLogLoss),
  tuneGrid = expand.grid(alpha = 1, lambda = seq(0, 1, by = 0.1)))

ed_lasso
```

## Third method: Classification tree

Next we predict the presence of diabetes using a classification tree, in which the predictor space is divided into various "regions", and the predicted value for any given observation is the most common classification among all other observations in that region. Classification trees are advantageous in that they are relatively easy to understand, and that they automatically account for interaction effects.  Here we train our model using 5-fold cross-validation as well as different tuning parameters to find the optimal number and types of tree splits.

```{r}
#classification tree
ed_ct <- train(Diabetes_binary_f ~ ., data = ed_train,
  method = "rpart",
  metric="logLoss",
  preProcess = c("center", "scale"),
  trControl = trainControl(method = "cv", number = 5, 
                           classProbs = TRUE, summaryFunction = mnLogLoss),
  tuneGrid = data.frame(cp = seq(from = .001, to = .1, by = .001)))

ed_ct
```

## Fourth method: Random forest

### Explanation of the random forest:
The random forest uses the same idea as bagging. It creates multiple trees from bootstrap samples and averages results. It uses a random subset of predictors for each bootstrap sample fit. 

### why we might use it instead of a basic classification tree:
We want to use random forest because we do not want to use all the predictors.If a really strong predictor exists, every bootstrap tree will probably use it for the first split and it will make the prediction more correlated.

```{r,eval=FALSE}
ed_rf<-train(Diabetes_binary_f~.,#BMI+HighBP_f+HighChol_f
             data=ed_train,
             method="rf", 
             metric="logLoss",
             trControl=trainControl(method = "cv",number = 5, classProbs=TRUE, summaryFunction=mnLogLoss),
             preProcess=c("center","scale"),
             tuneGrid=data.frame(mtry=c(5:7))
)
ed_rf
```
## Fifth method: rotation forest method

The rotation forest method is similar to the random forest method in that multiple models are brought to bear -- each having different numbers and combinations of predictors -- and the resulting set of predicted values are then averaged across models (or, in the case of a categorical outcome, the most prevalent classification across models is determined).  Unlike the random forest method, however, the rotation forest method first extracts principal components from the various sets of predictor variables that are considered, and enters the principal components as predictors (as opposed to directly entering the original predictor variables as is done when using random forest).  In more general terms, the rotation forest method is essentially a twist on the random forest method whereby principal component regression (or, principal component classification) is employed.  As such, the rotation forest method is particularly well-suited for dealing with any multi-collinearity that may exist among the predictors.  When training our model, we will use the default number of variable subsets (i.e. the number of subsets that results in 3 features per subset), and the default number of base classifiers (i.e. 10).  

```{r,eval=FALSE}
ed_rot <- train(Diabetes_binary_f ~ ., data = ed_train,
  method = "rotationForest",
  metric="logLoss",
  preProcess = c("center", "scale"),
  trControl = trainControl(method = "cv", number = 5, 
                           classProbs = TRUE, summaryFunction = mnLogLoss))

ed_rot
```


## Sixth method: Bayesian Generalized Linear Model

The generalized linear model (GLM) is an approach incorporating various probability distributions into a fitting procedure to describe variability. A GLM with Bayesian inference is often used to avoid over fitting. A Bayesian GLM can flexibly integrate various probability distributions as model residuals and parameter uncertainty.

```{r}
ed_bglm<-train(Diabetes_binary_f~.,data=ed_train,
             method="bayesglm", 
             metric="logLoss",
             trControl=trainControl(method = "cv",number = 5, classProbs=TRUE, summaryFunction=mnLogLoss),
             preProcess=c("center","scale")
)
ed_bglm
```

# Final Model Selection

We have six best models (one for each model type above). Now compare all six models on the test
set and declare an overall winner!

```{r}
# set a function to output logLoss value from each model by the test set
choose <- function(in_model)
{
pred <- predict(in_model, ed_test)
pred <- ifelse(pred=="no",0,1)
#as.data.frame is used here to avoid error as illustrated here: #https://www.statology.org/r-error-operator-is-invalid-for-atomic-vectors/
logLoss(actual = ed_test$Diabetes_binary_f, predicted = pred)
}

```

```{r}
ed_test$Diabetes_binary_f<-ifelse(ed_test$Diabetes_binary_f=="no",0,1)

# Method 1
# only output the best from method 1
a<-c("1","2","3")[which.min(c(ed_logistic1$results[2],ed_logistic2$results[2],ed_logistic3$results[2]))]
ifelse(a!=3,
       ifelse(a==1,
              CM1<-choose(in_model = ed_logistic1),
              CM1<-choose(in_model = ed_logistic2)
              ),
       CM1<-choose(in_model = ed_logistic3)
  )
paste0("logistic has a logLoss of ",CM1)

# Method 2
CM2<-choose(in_model = ed_lasso)
paste0("lasso has a logLoss of ",CM2)

# Method 3
CM3<-choose(in_model = ed_ct)
paste0("classification tree has a logLoss of ",CM3)

# Method 4
#CM4<-choose(in_model = ed_rf)
#paste0("random forests has a logLoss of ",CM4)

# Method 5
CM5<-choose(in_model = ed_rot)
paste0("rotation forests has a logLoss of ",CM5)

# Method 6
CM6<-choose(in_model = ed_bglm)
paste0("glm has a logLoss of ",CM6)
```
## Final conclusion
```{r}
CM<-c(CM1,CM2,CM3,#CM4,
      CM5,CM6)
paste0("model ",c("1","2","3",#"4",
                "5","6")[which.min(CM)]," is the best model")
```
End report!